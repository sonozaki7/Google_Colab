{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonozaki7/Google_Colab/blob/main/gpt4all_colab_terminal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej7ASjxNiKIt",
        "outputId": "bd9f2e03-645d-4c31-937d-8fd2f7dbce48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 1,475 kB of archives.\n",
            "After this operation, 5,959 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 122349 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.15.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.15.0-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.35.0-1build1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.35.0-1build1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.35.0-1build1_amd64.deb ...\n",
            "Unpacking aria2 (1.35.0-1build1) ...\n",
            "Setting up libc-ares2:amd64 (1.15.0-1ubuntu0.2) ...\n",
            "Setting up libaria2-0:amd64 (1.35.0-1build1) ...\n",
            "Setting up aria2 (1.35.0-1build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m810.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'gpt4all'...\n",
            "remote: Enumerating objects: 455, done.\u001b[K\n",
            "remote: Total 455 (delta 0), reused 0 (delta 0), pack-reused 455\u001b[K\n",
            "Receiving objects: 100% (455/455), 3.61 MiB | 30.07 MiB/s, done.\n",
            "Resolving deltas: 100% (255/255), done.\n",
            "Submodule 'peft' (https://github.com/huggingface/peft.git) registered for path 'peft'\n",
            "Submodule 'transformers' (https://github.com/huggingface/transformers.git) registered for path 'transformers'\n",
            "Cloning into '/content/gpt4all/peft'...\n",
            "remote: Enumerating objects: 2511, done.        \n",
            "remote: Counting objects: 100% (14/14), done.        \n",
            "remote: Compressing objects: 100% (14/14), done.        \n",
            "remote: Total 2511 (delta 5), reused 5 (delta 0), pack-reused 2497        \n",
            "Receiving objects: 100% (2511/2511), 7.63 MiB | 26.58 MiB/s, done.\n",
            "Resolving deltas: 100% (1590/1590), done.\n",
            "Cloning into '/content/gpt4all/transformers'...\n",
            "remote: Enumerating objects: 136039, done.        \n",
            "remote: Counting objects: 100% (81/81), done.        \n",
            "remote: Compressing objects: 100% (32/32), done.        \n",
            "remote: Total 136039 (delta 55), reused 73 (delta 49), pack-reused 135958        \n",
            "Receiving objects: 100% (136039/136039), 135.04 MiB | 20.84 MiB/s, done.\n",
            "Resolving deltas: 100% (102031/102031), done.\n",
            "Submodule path 'peft': checked out '098962fa6515f2e4fe83a757f5995d3ffbb1c373'\n",
            "Submodule path 'transformers': checked out 'cae78c46d658a8e496a815c2ee49b9b178fb9c9a'\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!apt -y install -qq aria2\n",
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!git clone --recurse-submodules -j8 https://github.com/camenduru/gpt4all\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/aryan1107/gpt4all-llora/resolve/main/gpt4all-lora-quantized.bin -d /content/gpt4all/chat -o gpt4all-lora-quantized.bin\n",
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm\n",
        "# Please copy and paste the code below in a terminal window. To paste, use Ctrl+Shift+V\n",
        "\n",
        "# cd /content/gpt4all/chat;./gpt4all-lora-quantized-linux-x86\n"
      ],
      "metadata": {
        "id": "XjsO3f8q-yRY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}